# RAG(검색 증강 생성)
#  - Retrieval Augmented Generation
#  - LLM 기본적으로 학습하는데 천문학적인 금액 소모
#     ㄴ LLM을 현재 학습했을 시점까지의 정보만 알고 있음
#     ㄴ 예를 들어, 2025년05월31일 학습을 한 모델의 경우 6월1일부터의 정보는 없음
#        문제점1: 최신 데이터 반영X
#        문제점2: 할루시네이션(환각) -> LLM 거짓말쟁이
#          -> RAG가 해결책

# ** RAG **
#  - Human(Query) -> LLM(GPT) -> Answer                  /기본구조
#  - Human(query) + 검색결과 -> LLM(GPT) -> Answer        /RAG구조

# 예를 들어: 삼성전자 모바일 사업부 갤럭시 QnA 챗봇을 개발 임무
#  ㄴ 기존에 LLM은 갤럭시 스마트폰에 대한 자세한 정보 X
#  ㄴ 사용자가 갤럭시에 대한 질문을 하면 그냥 보편적인 답변만 생성
#  ㄴ 갤럭시 스마트폰에 대한 정보가 담긴 PDF파일 생성
#  ㄴ 사용자의 질문과 유사한 정보를 Retrieval(검색)
#  ㄴ 검색 된 정보를 사용자 질문과 함께 LLM에 전달

# RAG 아키텍처
#  1. 지식 베이스
#   ㄴ 자료(PDF, PPT, ...) -> 불러오기(loader()) -> Chunk 단위로 분할
#     -> Text Embedding -> Vector DB에 저장

# * Text Embedding
#  - 단어 또는 문장을 1차원 숫자값의 나열로 변환 -> 벡터
#  - [1, 5, 3, 2, 7] -> 한 방향으로 죽 나열된 숫자값을 벡터라고 함
#  - 임베딩시 고려할 사항은 청크를 몇 개의 숫자로 표현?
#     ㄴ 1511개의 숫자로 표현

# PDF -> Chunk1 -> 벡터(5, 2, 12, ...) n=1521
#     -> Chunk2 -> 벡터(1, 52, 3, ...) n=1521
#     -> Chunk3 -> 벡터(99, 3, 4, ...) n=1521